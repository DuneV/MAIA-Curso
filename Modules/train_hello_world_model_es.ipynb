{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***Modelo de introducción en TensorFlow Lite***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adaptado de: Train a Simple TensorFlow Lite for Microcontrollers model de"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aCZBFzjClURz"
   },
   "source": [
    "Este cuaderno demuestra el proceso de entrenar un modelo simple en TensorFlow, convertirlo al formato TensorFlow Lite y luego optimizarlo para microcontroladores. El objetivo es crear un modelo que se pueda implementar fácilmente en dispositivos con recursos limitados, como microcontroladores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "5PYwRFppd-WB"
   },
   "outputs": [],
   "source": [
    "# Define las rutas de trabajo del modelo\n",
    "import os\n",
    "MODELS_DIR = 'models/'\n",
    "if not os.path.exists(MODELS_DIR):\n",
    "    os.mkdir(MODELS_DIR)\n",
    "MODEL_TF = MODELS_DIR + 'model'\n",
    "MODEL_NO_QUANT_TFLITE = MODELS_DIR + 'model_no_quant.tflite'\n",
    "MODEL_TFLITE = MODELS_DIR + 'model.tflite'\n",
    "MODEL_TFLITE_MICRO = MODELS_DIR + 'model.cc'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuración de Ambiente\n",
    "Instala las dependecias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cr1VLfotanf6",
    "outputId": "510567d6-300e-40e2-f5b8-c3520a3f3a8b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow==2.4.0\n",
      "  Downloading tensorflow-2.4.0-cp38-cp38-win_amd64.whl (370.7 MB)\n",
      "Collecting h5py~=2.10.0\n",
      "  Downloading h5py-2.10.0-cp38-cp38-win_amd64.whl (2.5 MB)\n",
      "Requirement already satisfied: protobuf>=3.9.2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow==2.4.0) (4.24.0)\n",
      "Collecting gast==0.3.3\n",
      "  Downloading gast-0.3.3-py2.py3-none-any.whl (9.7 kB)\n",
      "Collecting numpy~=1.19.2\n",
      "  Downloading numpy-1.19.5-cp38-cp38-win_amd64.whl (13.3 MB)\n",
      "Collecting keras-preprocessing~=1.1.2\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "Collecting termcolor~=1.1.0\n",
      "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
      "Collecting flatbuffers~=1.12.0\n",
      "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: google-pasta~=0.2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow==2.4.0) (0.2.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow==2.4.0) (1.6.3)\n",
      "Collecting six~=1.15.0\n",
      "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
      "Requirement already satisfied: wheel~=0.35 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow==2.4.0) (0.41.1)\n",
      "Collecting tensorflow-estimator<2.5.0,>=2.4.0rc0\n",
      "  Downloading tensorflow_estimator-2.4.0-py2.py3-none-any.whl (462 kB)\n",
      "Collecting typing-extensions~=3.7.4\n",
      "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
      "Collecting wrapt~=1.12.1\n",
      "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
      "Collecting absl-py~=0.10\n",
      "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
      "Collecting grpcio~=1.32.0\n",
      "  Downloading grpcio-1.32.0-cp38-cp38-win_amd64.whl (2.6 MB)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow==2.4.0) (3.3.0)\n",
      "Requirement already satisfied: tensorboard~=2.4 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorflow==2.4.0) (2.13.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (3.4.4)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.22.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (0.7.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (1.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.28.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (2.3.7)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from tensorboard~=2.4->tensorflow==2.4.0) (47.1.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4; python_version < \"3.10\" in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (6.8.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (4.9)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (1.26.12)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (5.3.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.4->tensorflow==2.4.0) (1.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2022.9.24)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow==2.4.0) (3.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.4->tensorflow==2.4.0) (2.1.3)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from importlib-metadata>=4.4; python_version < \"3.10\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow==2.4.0) (3.16.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard~=2.4->tensorflow==2.4.0) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard~=2.4->tensorflow==2.4.0) (3.2.2)\n",
      "Building wheels for collected packages: termcolor, wrapt\n",
      "  Building wheel for termcolor (setup.py): started\n",
      "  Building wheel for termcolor (setup.py): finished with status 'done'\n",
      "  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4853 sha256=2fed94e0dde4c9579ce9e41c295468dda3819e580b37d8a1e8a25584d7f70224\n",
      "  Stored in directory: c:\\users\\danie\\appdata\\local\\pip\\cache\\wheels\\a0\\16\\9c\\5473df82468f958445479c59e784896fa24f4a5fc024b0f501\n",
      "  Building wheel for wrapt (setup.py): started\n",
      "  Building wheel for wrapt (setup.py): finished with status 'done'\n",
      "  Created wheel for wrapt: filename=wrapt-1.12.1-cp38-cp38-win_amd64.whl size=33844 sha256=fb9c4536b871840c0a9dd01c57ee6e64effcf10f57c5da772cd063c77dd3383e\n",
      "  Stored in directory: c:\\users\\danie\\appdata\\local\\pip\\cache\\wheels\\5f\\fd\\9e\\b6cf5890494cb8ef0b5eaff72e5d55a70fb56316007d6dfe73\n",
      "Successfully built termcolor wrapt\n",
      "Installing collected packages: six, numpy, h5py, gast, keras-preprocessing, termcolor, flatbuffers, tensorflow-estimator, typing-extensions, wrapt, absl-py, grpcio, tensorflow\n",
      "  Attempting uninstall: six\n",
      "    Found existing installation: six 1.16.0\n",
      "    Uninstalling six-1.16.0:\n",
      "      Successfully uninstalled six-1.16.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.23.4\n",
      "    Uninstalling numpy-1.23.4:\n",
      "      Successfully uninstalled numpy-1.23.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: tensorflow-intel 2.13.0 has requirement absl-py>=1.0.0, but you'll have absl-py 0.15.0 which is incompatible.\n",
      "ERROR: tensorflow-intel 2.13.0 has requirement flatbuffers>=23.1.21, but you'll have flatbuffers 1.12 which is incompatible.\n",
      "ERROR: tensorflow-intel 2.13.0 has requirement numpy<=1.24.3,>=1.22, but you'll have numpy 1.19.5 which is incompatible.\n",
      "ERROR: tensorflow-intel 2.13.0 has requirement tensorflow-estimator<2.14,>=2.13.0, but you'll have tensorflow-estimator 2.4.0 which is incompatible.\n",
      "ERROR: tensorboard 2.13.0 has requirement grpcio>=1.48.2, but you'll have grpcio 1.32.0 which is incompatible.\n",
      "ERROR: sqlalchemy 2.0.19 has requirement typing-extensions>=4.2.0, but you'll have typing-extensions 3.7.4.3 which is incompatible.\n",
      "ERROR: pyvista 0.43.5 has requirement numpy>=1.21.0, but you'll have numpy 1.19.5 which is incompatible.\n",
      "ERROR: pypdf2 3.0.1 has requirement typing_extensions>=3.10.0.0; python_version < \"3.10\", but you'll have typing-extensions 3.7.4.3 which is incompatible.\n",
      "ERROR: pydantic 1.10.12 has requirement typing-extensions>=4.2.0, but you'll have typing-extensions 3.7.4.3 which is incompatible.\n",
      "ERROR: pandas 1.5.0 has requirement numpy>=1.20.3; python_version < \"3.10\", but you'll have numpy 1.19.5 which is incompatible.\n",
      "ERROR: Could not install packages due to an EnvironmentError: [WinError 5] Acceso denegado: 'C:\\\\Users\\\\danie\\\\AppData\\\\Local\\\\Programs\\\\Python\\\\Python38\\\\Lib\\\\site-packages\\\\~umpy\\\\.libs\\\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: You are using pip version 20.1.1; however, version 24.0 is available.\n",
      "You should consider upgrading via the 'c:\\users\\danie\\appdata\\local\\programs\\python\\python38\\python.exe -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow==2.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Importa las dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TensorFlow is an open source machine learning library\n",
    "import tensorflow as tf\n",
    "\n",
    "# Keras is TensorFlow's high-level API for deep learning\n",
    "from tensorflow import keras\n",
    "# Numpy is a math library\n",
    "import numpy as np\n",
    "# Pandas is a data manipulation library\n",
    "import pandas as pd\n",
    "# Matplotlib is a graphing library\n",
    "import matplotlib.pyplot as plt\n",
    "# Math is Python's math library\n",
    "import math\n",
    "\n",
    "# Set seed for experiment reproducibility\n",
    "seed = 1\n",
    "np.random.seed(seed)\n",
    "tf.random.set_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base de Datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generar los datos\n",
    "El código de la siguiente celda generará un conjunto de valores \"x\" aleatorios, calculará sus valores senos y los mostrará en un gráfico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of sample datapoints\n",
    "SAMPLES = 1000\n",
    "\n",
    "# Generate a uniformly distributed set of random numbers in the range from\n",
    "# 0 to 2π, which covers a complete sine wave oscillation\n",
    "x_values = np.random.uniform(\n",
    "    low=0, high=2*math.pi, size=SAMPLES).astype(np.float32)\n",
    "\n",
    "# Shuffle the values to guarantee they're not in order\n",
    "np.random.shuffle(x_values)\n",
    "\n",
    "# Calculate the corresponding sine values\n",
    "y_values = np.sin(x_values).astype(np.float32)\n",
    "\n",
    "# Plot our data. The 'b.' argument tells the library to print blue dots.\n",
    "plt.plot(x_values, y_values, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Añadir Ruido\n",
    "Dado que fueron generados directamente por la función seno, nuestros datos se ajustan a una curva agradable y suave.\n",
    "\n",
    "Sin embargo, los modelos de aprendizaje automático son buenos para extraer el significado subyacente de datos confusos del mundo real. Para demostrar esto, podemos agregar algo de ruido a nuestros datos para aproximarnos a algo más realista.\n",
    "\n",
    "En la siguiente celda, agregaremos algo de ruido aleatorio a cada valor y luego dibujaremos un nuevo gráfico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a small random number to each y value\n",
    "y_values += 0.1 * np.random.randn(*y_values.shape)\n",
    "\n",
    "# Plot our data\n",
    "plt.plot(x_values, y_values, 'b.')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Dividir los Datos\n",
    "Ahora tenemos un conjunto de datos ruidoso que se aproxima a los datos del mundo real. Usaremos esto para entrenar nuestro modelo.\n",
    "\n",
    "Para evaluar la precisión del modelo que entrenamos, necesitaremos comparar sus predicciones con datos reales y comprobar qué tan bien coinciden. Esta evaluación ocurre durante el entrenamiento (donde se denomina validación) y después del entrenamiento (lo que se denomina prueba). En ambos casos es importante que utilicemos datos nuevos que no se hayan utilizado ya para entrenar el modelo.\n",
    "\n",
    "Los datos se dividen de la siguiente manera:\n",
    "   1. Formación: 60%\n",
    "   2. Validación: 20%\n",
    "   3. Pruebas: 20%\n",
    "\n",
    "El siguiente código dividirá nuestros datos y luego trazará cada conjunto con un color diferente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use 60% of our data for training and 20% for testing. The remaining 20%\n",
    "# will be used for validation. Calculate the indices of each section.\n",
    "TRAIN_SPLIT =  int(0.6 * SAMPLES)\n",
    "TEST_SPLIT = int(0.2 * SAMPLES + TRAIN_SPLIT)\n",
    "\n",
    "# Use np.split to chop our data into three parts.\n",
    "# The second argument to np.split is an array of indices where the data will be\n",
    "# split. We provide two indices, so the data will be divided into three chunks.\n",
    "x_train, x_test, x_validate = np.split(x_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "y_train, y_test, y_validate = np.split(y_values, [TRAIN_SPLIT, TEST_SPLIT])\n",
    "\n",
    "# Double check that our splits add up correctly\n",
    "assert (x_train.size + x_validate.size + x_test.size) ==  SAMPLES\n",
    "\n",
    "# Plot the data in each partition in different colors:\n",
    "plt.plot(x_train, y_train, 'b.', label=\"Train\")\n",
    "plt.plot(x_test, y_test, 'r.', label=\"Test\")\n",
    "plt.plot(x_validate, y_validate, 'y.', label=\"Validate\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Diseñar el modelo\n",
    "Vamos a construir un modelo de red neuronal simple que tomará un valor de entrada (en este caso, \"x\") y lo usará para predecir un valor de salida numérico (el seno de \"x\"). Este tipo de problema se llama _regresión_. Utilizará _capas_ de _neuronas_ para intentar aprender cualquier patrón subyacente a los datos de entrenamiento, de modo que pueda hacer predicciones.\n",
    "\n",
    "Para empezar, definiremos dos capas. La primera capa toma una única entrada (nuestro valor \"x\") y la ejecuta a través de 8 neuronas. Según esta entrada, cada neurona se _activará_ hasta cierto punto según su estado interno (sus valores de _peso_ y _sesgo_). El grado de activación de una neurona se expresa como un número.\n",
    "\n",
    "Los números de activación de nuestra primera capa se enviarán como entradas a nuestra segunda capa, que es una sola neurona. Aplicará sus propios pesos y sesgos a estas entradas y calculará su propia activación, que se generará como nuestro valor \"y\".\n",
    "\n",
    "**Nota:** Para obtener más información sobre cómo funcionan las redes neuronales, puede explorar los codelabs de [Aprenda TensorFlow](https://codelabs.developers.google.com/codelabs/tensorflow-lab1-helloworld).\n",
    "\n",
    "El código de la siguiente celda define nuestro modelo utilizando [Keras](https://www.tensorflow.org/guide/keras), la API de alto nivel de TensorFlow para crear redes de aprendizaje profundo. Una vez definida la red, la _compilamos_, especificando parámetros que determinan cómo será entrenada:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use Keras to create a simple model architecture\n",
    "model_1 = tf.keras.Sequential()\n",
    "\n",
    "# First layer takes a scalar input and feeds it through 8 \"neurons\". The\n",
    "# neurons decide whether to activate based on the 'relu' activation function.\n",
    "model_1.add(keras.layers.Dense(8, activation='relu', input_shape=(1,)))\n",
    "\n",
    "# Final layer is a single neuron, since we want to output a single value\n",
    "model_1.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
    "model_1.compile(optimizer='adam', loss='mse', metrics=['mae'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Entrenar el modelo\n",
    "Una vez que hayamos definido el modelo, podemos usar nuestros datos para _entrenarlo_. El entrenamiento implica pasar un valor \"x\" a la red neuronal, verificar en qué medida se desvía la salida de la red del valor \"y\" esperado y ajustar los pesos y sesgos de las neuronas para que sea más probable que la salida sea correcta la próxima vez.\n",
    "\n",
    "El entrenamiento ejecuta este proceso en el conjunto de datos completo varias veces, y cada ejecución completa se conoce como una _época_. La cantidad de épocas que se ejecutarán durante el entrenamiento es un parámetro que podemos establecer.\n",
    "\n",
    "Durante cada época, los datos se ejecutan a través de la red en múltiples _lotes_. En cada lote, se pasan varios datos a la red, lo que produce valores de salida. La exactitud de estos resultados se mide de forma agregada y las ponderaciones y sesgos de la red se ajustan en consecuencia, una vez por lote. El _tamaño del lote_ también es un parámetro que podemos configurar.\n",
    "\n",
    "El código de la siguiente celda utiliza los valores \"x\" e \"y\" de nuestros datos de entrenamiento para entrenar el modelo. Se ejecuta durante 500 _épocas_, con 64 datos en cada _lote_. También pasamos algunos datos para _validación_. Como verá cuando ejecute el celular, el entrenamiento puede tardar un poco en completarse:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model on our training data while validating on our validation set\n",
    "history_1 = model_1.fit(x_train, y_train, epochs=500, batch_size=64,\n",
    "                        validation_data=(x_validate, y_validate))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Graficar métricas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Pérdida (o error cuadrático medio)**\n",
    "\n",
    "Durante el entrenamiento, el rendimiento del modelo se mide constantemente en comparación con nuestros datos de entrenamiento y los datos de validación que reservamos anteriormente. El entrenamiento produce un registro de datos que nos dice cómo cambió el rendimiento del modelo durante el transcurso del proceso de entrenamiento.\n",
    "\n",
    "Las siguientes celdas mostrarán algunos de esos datos en forma gráfica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a graph of the loss, which is the distance between\n",
    "# the predicted and actual values during training and validation.\n",
    "train_loss = history_1.history['loss']\n",
    "val_loss = history_1.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "plt.plot(epochs, train_loss, 'g.', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico muestra la _pérdida_ (o la diferencia entre las predicciones del modelo y los datos reales) para cada época. Hay varias formas de calcular la pérdida y el método que hemos utilizado es el _error cuadrático medio_. Hay un valor de pérdida distinto dado para los datos de entrenamiento y validación.\n",
    "\n",
    "Como podemos ver, la cantidad de pérdida disminuye rápidamente durante las primeras 25 épocas, antes de estabilizarse. ¡Esto significa que el modelo está mejorando y produciendo predicciones más precisas!\n",
    "\n",
    "Nuestro objetivo es detener el entrenamiento cuando el modelo ya no mejora o cuando la _pérdida de entrenamiento_ es menor que la _pérdida de validación_, lo que significaría que el modelo ha aprendido a predecir los datos de entrenamiento tan bien que ya no puede generalizarlos a nuevos. datos.\n",
    "\n",
    "Para que la parte más plana del gráfico sea más legible, omitamos las primeras 50 épocas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the first few epochs so the graph is easier to read\n",
    "SKIP = 50\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el gráfico, podemos ver que la pérdida continúa reduciéndose hasta aproximadamente 200 épocas, momento en el que es mayoritariamente estable. Esto significa que no es necesario entrenar nuestra red más allá de 200 épocas.\n",
    "\n",
    "Sin embargo, también podemos ver que el valor de pérdida más bajo sigue siendo de alrededor de 0,155. Esto significa que las predicciones de nuestra red están equivocadas en un promedio de ~15%. Además, los valores de pérdida de validación varían mucho y, a veces, son incluso mayores.\n",
    "\n",
    "**2. Error absoluto medio**\n",
    "\n",
    "Para obtener más información sobre el rendimiento de nuestro modelo, podemos trazar algunos datos más. Esta vez, trazaremos el _error absoluto medio_, que es otra forma de medir qué tan lejos están las predicciones de la red de los números reales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "\n",
    "# Draw a graph of mean absolute error, which is another way of\n",
    "# measuring the amount of error in the prediction.\n",
    "train_mae = history_1.history['mae']\n",
    "val_mae = history_1.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este gráfico de _error absoluto medio_ cuenta otra historia. Podemos ver que los datos de entrenamiento muestran consistentemente un error menor que los datos de validación, lo que significa que la red puede haberse sobreajustado o haber aprendido los datos de entrenamiento de manera tan rígida que no puede hacer predicciones efectivas sobre nuevos datos.\n",
    "\n",
    "Además, los valores medios de error absoluto son bastante altos, ~0,305 en el mejor de los casos, lo que significa que algunas de las predicciones del modelo tienen al menos un 30 % de error. Un error del 30% significa que estamos muy lejos de modelar con precisión la función de onda sinusoidal.\n",
    "\n",
    "**3. Resultados reales versus previstos**\n",
    "\n",
    "Para obtener más información sobre lo que está sucediendo, verifiquemos sus predicciones con el conjunto de datos de prueba que reservamos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the loss on our test dataset\n",
    "test_loss, test_mae = model_1.evaluate(x_test, y_test)\n",
    "\n",
    "# Make predictions based on our test dataset\n",
    "y_test_pred = model_1.predict(x_test)\n",
    "\n",
    "# Graph the predictions against the actual values\n",
    "plt.clf()\n",
    "plt.title('Comparison of predictions and actual values')\n",
    "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
    "plt.plot(x_test, y_test_pred, 'r.', label='TF predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Oh querido! El gráfico deja claro que nuestra red ha aprendido a aproximarse a la función seno de una forma muy limitada.\n",
    "\n",
    "La rigidez de este ajuste sugiere que el modelo no tiene suficiente capacidad para aprender toda la complejidad de la función de onda sinusoidal, por lo que sólo puede aproximarla de una manera demasiado simplista. Al hacer nuestro modelo más grande, deberíamos poder mejorar su rendimiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenando un modelo más grande"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Diseñar el modelo\n",
    "Para agrandar nuestro modelo, agreguemos una capa adicional de neuronas. La siguiente celda redefine nuestro modelo de la misma manera que antes, pero con 16 neuronas en la primera capa y una capa adicional de 16 neuronas en el medio:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "# First layer takes a scalar input and feeds it through 16 \"neurons\". The\n",
    "# neurons decide whether to activate based on the 'relu' activation function.\n",
    "model.add(keras.layers.Dense(16, activation='relu', input_shape=(1,)))\n",
    "\n",
    "# The new second and third layer will help the network learn more complex representations\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "\n",
    "# Final layer is a single neuron, since we want to output a single value\n",
    "model.add(keras.layers.Dense(1))\n",
    "\n",
    "# Compile the model using the standard 'adam' optimizer and the mean squared error or 'mse' loss function for regression.\n",
    "model.compile(optimizer='adam', loss=\"mse\", metrics=[\"mae\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Entrenar el modelo ###\n",
    "\n",
    "Ahora entrenaremos y guardaremos el nuevo modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(x_train, y_train, epochs=500, batch_size=64,\n",
    "                    validation_data=(x_validate, y_validate))\n",
    "\n",
    "# Save the model to disk\n",
    "model.save(MODEL_TF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Métricas de trazado\n",
    "En cada época de entrenamiento, el modelo imprime su pérdida y su error absoluto medio para el entrenamiento y la validación. Puede leer esto en el resultado anterior (tenga en cuenta que sus números exactos pueden diferir):\n",
    "\n",
    "```\n",
    "Época 500/500\n",
    "10/10 [==============================] - 0s 10ms/paso - pérdida: 0.0121 - mae: 0.0882 - val_loss : 0,0115 - val_mae: 0,0865\n",
    "```\n",
    "\n",
    "Puede ver que ya hemos logrado una gran mejora: la pérdida de validación se redujo de 0,15 a 0,01 y el MAE de validación se redujo de 0,33 a 0,08.\n",
    "\n",
    "La siguiente celda imprimirá los mismos gráficos que usamos para evaluar nuestro modelo original, pero mostrando nuestro nuevo historial de entrenamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw a graph of the loss, which is the distance between\n",
    "# the predicted and actual values during training and validation.\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(train_loss) + 1)\n",
    "\n",
    "# Exclude the first few epochs so the graph is easier to read\n",
    "SKIP = 100\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_loss[SKIP:], 'g.', label='Training loss')\n",
    "plt.plot(epochs[SKIP:], val_loss[SKIP:], 'b.', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "\n",
    "# Draw a graph of mean absolute error, which is another way of\n",
    "# measuring the amount of error in the prediction.\n",
    "train_mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "plt.plot(epochs[SKIP:], train_mae[SKIP:], 'g.', label='Training MAE')\n",
    "plt.plot(epochs[SKIP:], val_mae[SKIP:], 'b.', label='Validation MAE')\n",
    "plt.title('Training and validation mean absolute error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Buenos resultados! En estos gráficos, podemos ver varias cosas interesantes:\n",
    "\n",
    "* La pérdida general y MAE son mucho mejores que nuestra red anterior.\n",
    "* Las métricas son mejores para la validación que para la capacitación, lo que significa que la red no está sobreadaptada\n",
    "\n",
    "La razón por la que las métricas de validación son mejores que las de entrenamiento es que las métricas de validación se calculan al final de cada época, mientras que las métricas de entrenamiento se calculan a lo largo de la época, por lo que la validación ocurre en un modelo que ha sido entrenado un poco más.\n",
    "\n",
    "¡Todo esto significa que nuestra red parece estar funcionando bien! Para confirmar, verifiquemos sus predicciones con el conjunto de datos de prueba que reservamos anteriormente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and print the loss on our test dataset\n",
    "test_loss, test_mae = model.evaluate(x_test, y_test)\n",
    "\n",
    "# Make predictions based on our test dataset\n",
    "y_test_pred = model.predict(x_test)\n",
    "\n",
    "# Graph the predictions against the actual values\n",
    "plt.clf()\n",
    "plt.title('Comparison of predictions and actual values')\n",
    "plt.plot(x_test, y_test, 'b.', label='Actual values')\n",
    "plt.plot(x_test, y_test_pred, 'r.', label='TF predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¡Mucho mejor! Las métricas de evaluación que imprimimos muestran que el modelo tiene una pérdida baja y MAE en los datos de prueba, y las predicciones se alinean visualmente con nuestros datos bastante bien.\n",
    "\n",
    "El modelo no es perfecto; sus predicciones no forman una curva sinusoidal suave. Por ejemplo, la línea es casi recta cuando \"x\" está entre 4,2 y 5,2. Si quisiéramos ir más allá, podríamos intentar aumentar aún más la capacidad del modelo, tal vez utilizando algunas técnicas para defendernos del sobreajuste.\n",
    "\n",
    "Sin embargo, una parte importante del aprendizaje automático es *saber cuándo detenerse*. Este modelo es lo suficientemente bueno para nuestro caso de uso, que consiste en hacer que algunos LED parpadeen en un patrón agradable.\n",
    "\n",
    "## Generar un modelo de TensorFlow Lite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Generar Modelos con o sin Cuantización\n",
    "Ahora tenemos un modelo aceptablemente preciso. Usaremos el [TensorFlow Lite Converter](https://www.tensorflow.org/lite/convert) para convertir el modelo a un formato especial que ocupa poco espacio para usarlo en dispositivos con memoria limitada.\n",
    "\n",
    "Dado que este modelo se implementará en un microcontrolador, ¡queremos que sea lo más pequeño posible! Una técnica para reducir el tamaño de un modelo se llama [cuantización] (https://www.tensorflow.org/lite/performance/post_training_quantization). Reduce la precisión de los pesos del modelo y posiblemente también las activaciones (salida de cada capa), lo que ahorra memoria, a menudo sin mucho impacto en la precisión. Los modelos cuantificados también funcionan más rápido, ya que los cálculos necesarios son más sencillos.\n",
    "\n",
    "En la siguiente celda, convertiremos el modelo dos veces: una con cuantificación y otra sin cuantización."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "uKjg7QeMDsDx",
    "outputId": "2ded7790-62a2-40df-a4f9-429f2dd5357f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Convert the model to the TensorFlow Lite format without quantization\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(MODEL_TF)\n",
    "model_no_quant_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_NO_QUANT_TFLITE, \"wb\").write(model_no_quant_tflite)\n",
    "\n",
    "# Convert the model to the TensorFlow Lite format with quantization\n",
    "def representative_dataset():\n",
    "  for i in range(500):\n",
    "    yield([x_train[i].reshape(1, 1)])\n",
    "# Set the optimization flag.\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "# Enforce integer only quantization\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Provide a representative dataset to ensure we quantize correctly.\n",
    "converter.representative_dataset = representative_dataset\n",
    "model_tflite = converter.convert()\n",
    "\n",
    "# Save the model to disk\n",
    "open(MODEL_TFLITE, \"wb\").write(model_tflite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Comparar el rendimiento del modelo\n",
    "\n",
    "Para demostrar que estos modelos son precisos incluso después de la conversión y cuantificación, compararemos sus predicciones y pérdidas en nuestro conjunto de datos de prueba.\n",
    "\n",
    "**Funciones auxiliares**\n",
    "\n",
    "Definimos las funciones \"predecir\" (para predicciones) y \"evaluar\" (para pérdidas) para los modelos TFLite. *Nota: Estos ya están incluidos en un modelo TF, pero no en un modelo TFLite.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tflite(tflite_model, x_test):\n",
    "    # Prepare the test data\n",
    "    x_test_ = x_test.copy()\n",
    "    x_test_ = x_test_.reshape((x_test.size, 1))\n",
    "    x_test_ = x_test_.astype(np.float32)\n",
    "\n",
    "    # Initialize the TFLite interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_content=tflite_model,\n",
    "                                        experimental_op_resolver_type=tf.lite.experimental.OpResolverType.BUILTIN_REF)\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    # If required, quantize the input layer (from float to integer)\n",
    "    input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "    if (input_scale, input_zero_point) != (0.0, 0):\n",
    "        x_test_ = x_test_ / input_scale + input_zero_point\n",
    "        x_test_ = x_test_.astype(input_details[\"dtype\"])\n",
    "\n",
    "    # Invoke the interpreter\n",
    "    y_pred = np.empty(x_test_.size, dtype=output_details[\"dtype\"])\n",
    "    for i in range(len(x_test_)):\n",
    "        interpreter.set_tensor(input_details[\"index\"], [x_test_[i]])\n",
    "        interpreter.invoke()\n",
    "        y_pred[i] = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "    # If required, dequantized the output layer (from integer to float)\n",
    "    output_scale, output_zero_point = output_details[\"quantization\"]\n",
    "    if (output_scale, output_zero_point) != (0.0, 0):\n",
    "        y_pred = y_pred.astype(np.float32)\n",
    "        y_pred = (y_pred - output_zero_point) * output_scale\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "def evaluate_tflite(tflite_model, x_test, y_true):\n",
    "    global model\n",
    "    y_pred = predict_tflite(tflite_model, x_test)\n",
    "    loss_function = tf.keras.losses.get(model.loss)\n",
    "    loss = loss_function(y_true, y_pred).numpy()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Predicciones**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate predictions\n",
    "y_test_pred_tf = model.predict(x_test)\n",
    "y_test_pred_no_quant_tflite = predict_tflite(model_no_quant_tflite, x_test)\n",
    "y_test_pred_tflite = predict_tflite(model_tflite, x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare predictions\n",
    "plt.clf()\n",
    "plt.title('Comparison of various models against actual values')\n",
    "plt.plot(x_test, y_test, 'bo', label='Actual values')\n",
    "plt.plot(x_test, y_test_pred_tf, 'ro', label='TF predictions')\n",
    "plt.plot(x_test, y_test_pred_no_quant_tflite, 'bx', label='TFLite predictions')\n",
    "plt.plot(x_test, y_test_pred_tflite, 'gx', label='TFLite quantized predictions')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Perdida (MSE)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate loss\n",
    "loss_tf, _ = model.evaluate(x_test, y_test, verbose=0)\n",
    "loss_no_quant_tflite = evaluate_tflite(model_no_quant_tflite, x_test, y_test)\n",
    "loss_tflite = evaluate_tflite(model_tflite, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare loss\n",
    "df = pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", loss_tf],\n",
    "     [\"TensorFlow Lite\", loss_no_quant_tflite],\n",
    "     [\"TensorFlow Lite Quantized\", loss_tflite]],\n",
    "     columns = [\"Model\", \"Loss/MSE\"], index=\"Model\").round(4)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Tamaño**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate size\n",
    "size_tf = os.path.getsize(MODEL_TF)\n",
    "size_no_quant_tflite = os.path.getsize(MODEL_NO_QUANT_TFLITE)\n",
    "size_tflite = os.path.getsize(MODEL_TFLITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare size\n",
    "pd.DataFrame.from_records(\n",
    "    [[\"TensorFlow\", f\"{size_tf} bytes\", \"\"],\n",
    "     [\"TensorFlow Lite\", f\"{size_no_quant_tflite} bytes \", f\"(reduced by {size_tf - size_no_quant_tflite} bytes)\"],\n",
    "     [\"TensorFlow Lite Quantized\", f\"{size_tflite} bytes\", f\"(reduced by {size_no_quant_tflite - size_tflite} bytes)\"]],\n",
    "     columns = [\"Model\", \"Size\", \"\"], index=\"Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resúmen**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver en las predicciones (gráfico) y la pérdida (tabla) que el modelo TF original, el modelo TFLite y el modelo TFLite cuantificado son lo suficientemente cercanos como para ser indistinguibles, aunque difieren en tamaño (tabla). ¡Esto implica que el modelo cuantificado (el más pequeño) está listo para usar!\n",
    "\n",
    "*Nota: El modelo TFLite cuantificado (entero) es solo 300 bytes más pequeño que el modelo TFLite original (flotante): ¡una pequeña reducción de tamaño! Esto se debe a que el modelo ya es tan pequeño que la cuantificación tiene poco efecto. ¡Los modelos complejos con más peso pueden tener una reducción de tamaño de hasta 4 veces!*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generar un modelo de TensorFlow Lite para microcontroladores\n",
    "Convierta el modelo cuantificado de TensorFlow Lite en un archivo fuente C que TensorFlow Lite para microcontroladores pueda cargar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install xxd if it is not available\n",
    "!apt-get update && apt-get -qq install xxd\n",
    "# Convert to a C source file, i.e, a TensorFlow Lite for Microcontrollers model\n",
    "!xxd -i {MODEL_TFLITE} > {MODEL_TFLITE_MICRO}\n",
    "# Update variable names\n",
    "REPLACE_TEXT = MODEL_TFLITE.replace('/', '_').replace('.', '_')\n",
    "!sed -i 's/'{REPLACE_TEXT}'/g_model/g' {MODEL_TFLITE_MICRO}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementar en un microcontrolador\n",
    "\n",
    "Siga las instrucciones en [hello_world](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world) README.md para [TensorFlow Lite para microcontroladores](https: //www.tensorflow.org/lite/microcontrollers/overview) para implementar este modelo en un microcontrolador específico.\n",
    "\n",
    "**Modelo de referencia:** Si no ha modificado este cuaderno, puede seguir las instrucciones tal como están para implementar el modelo. Consulte el directorio [`hello_world/train/models`](https://github.com/tensorflow/tflite-micro/blob/main/tensorflow/lite/micro/examples/hello_world/train/models) para acceder a los modelos. generado en este cuaderno.\n",
    "\n",
    "**Nuevo modelo:** Si ha generado un nuevo modelo, actualice los valores asignados a las variables definidas en [`hello_world/model.cc`](https://github.com/tensorflow/tflite-micro/blob /main/tensorflow/lite/micro/examples/hello_world/model.cc) con valores mostrados después de ejecutar la siguiente celda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the C source file\n",
    "!cat {MODEL_TFLITE_MICRO}"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "train_hello_world_model.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "22cb1d09959a40fdc50ccd77b5464bb60602aea13b58d7f13d7eaffcd0bc7c7d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
